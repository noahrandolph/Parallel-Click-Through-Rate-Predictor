{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "W261 Machine Learning at Scale<br>\n",
    "12 December 2018\n",
    "\n",
    "Wei Wang;\n",
    "Alice Lam;\n",
    "John Tabbone;\n",
    "Noah Randolph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Formulation\n",
    "\n",
    "Alice Lam: \"enhancing CTR means improved monetization of your current traffic (eyeballs/views). The algorithm to predict CTR accurately is useful for the platform to show specific ads to specific people who would have the highest CTR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA & Discussion of Challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing eda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile eda.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"eda\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .getOrCreate()\n",
    "        \n",
    "sc = spark.sparkContext\n",
    "\n",
    "# load the data into Spark dataframes\n",
    "df = spark.read.csv('gs://w261_final_project/train.txt', sep='\\t')\n",
    "\n",
    "# split into test and training data\n",
    "splits = df.randomSplit([0.2, 0.8], seed=2615)\n",
    "testDf = splits[0]\n",
    "trainDf = splits[1]\n",
    "\n",
    "print(df.columns)\n",
    "print(testDf.count())\n",
    "print(trainDf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.5/site-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
      "    from google.appengine.api import memcache\n",
      "ImportError: No module named 'google.appengine'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.5/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ImportError: No module named 'oauth2client.contrib.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.5/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ImportError: No module named 'oauth2client.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.5/site-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"/anaconda3/lib/python3.5/site-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
      "    'file_cache is unavailable when using oauth2client >= 4.0.0')\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n",
      "Creating cluster...\n",
      "Waiting for cluster creation...\n",
      "Cluster created.\n",
      "Uploading pyspark file to GCS\n",
      "testcluster - RUNNING\n",
      "Submitted job ID 5982d406-f224-45bf-9751-8385bf7a1406\n",
      "Waiting for job to finish...\n",
      "Job finished.\n",
      "Downloading output file\n",
      "Received job output b\"Ivy Default Cache set to: /root/.ivy2/cache\\nThe jars for the packages stored in: /root/.ivy2/jars\\n:: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\\ncom.databricks#spark-xml_2.11 added as a dependency\\ngraphframes#graphframes added as a dependency\\ncom.databricks#spark-avro_2.11 added as a dependency\\n:: resolving dependencies :: org.apache.spark#spark-submit-parent;1.0\\n\\tconfs: [default]\\n\\tfound com.databricks#spark-xml_2.11;0.4.1 in central\\n\\tfound graphframes#graphframes;0.5.0-spark2.1-s_2.11 in spark-packages\\n\\tfound com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 in central\\n\\tfound com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 in central\\n\\tfound org.scala-lang#scala-reflect;2.11.0 in central\\n\\tfound org.slf4j#slf4j-api;1.7.7 in central\\n\\tfound com.databricks#spark-avro_2.11;4.0.0 in central\\n\\tfound org.apache.avro#avro;1.7.6 in central\\n\\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\\n\\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\\n\\tfound com.thoughtworks.paranamer#paranamer;2.3 in central\\n\\tfound org.xerial.snappy#snappy-java;1.0.5 in central\\n\\tfound org.apache.commons#commons-compress;1.4.1 in central\\n\\tfound org.tukaani#xz;1.0 in central\\ndownloading https://repo1.maven.org/maven2/com/databricks/spark-xml_2.11/0.4.1/spark-xml_2.11-0.4.1.jar ...\\n\\t[SUCCESSFUL ] com.databricks#spark-xml_2.11;0.4.1!spark-xml_2.11.jar (42ms)\\ndownloading http://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.5.0-spark2.1-s_2.11/graphframes-0.5.0-spark2.1-s_2.11.jar ...\\n\\t[SUCCESSFUL ] graphframes#graphframes;0.5.0-spark2.1-s_2.11!graphframes.jar (393ms)\\ndownloading https://repo1.maven.org/maven2/com/databricks/spark-avro_2.11/4.0.0/spark-avro_2.11-4.0.0.jar ...\\n\\t[SUCCESSFUL ] com.databricks#spark-avro_2.11;4.0.0!spark-avro_2.11.jar (23ms)\\ndownloading https://repo1.maven.org/maven2/com/typesafe/scala-logging/scala-logging-api_2.11/2.1.2/scala-logging-api_2.11-2.1.2.jar ...\\n\\t[SUCCESSFUL ] com.typesafe.scala-logging#scala-logging-api_2.11;2.1.2!scala-logging-api_2.11.jar (12ms)\\ndownloading https://repo1.maven.org/maven2/com/typesafe/scala-logging/scala-logging-slf4j_2.11/2.1.2/scala-logging-slf4j_2.11-2.1.2.jar ...\\n\\t[SUCCESSFUL ] com.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2!scala-logging-slf4j_2.11.jar (13ms)\\ndownloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.11.0/scala-reflect-2.11.0.jar ...\\n\\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.11.0!scala-reflect.jar (464ms)\\ndownloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.7/slf4j-api-1.7.7.jar ...\\n\\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.7!slf4j-api.jar (13ms)\\ndownloading https://repo1.maven.org/maven2/org/apache/avro/avro/1.7.6/avro-1.7.6.jar ...\\n\\t[SUCCESSFUL ] org.apache.avro#avro;1.7.6!avro.jar(bundle) (50ms)\\ndownloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar ...\\n\\t[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.9.13!jackson-core-asl.jar (29ms)\\ndownloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar ...\\n\\t[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.9.13!jackson-mapper-asl.jar (84ms)\\ndownloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...\\n\\t[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (14ms)\\ndownloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar ...\\n\\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.5!snappy-java.jar(bundle) (110ms)\\ndownloading https://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar ...\\n\\t[SUCCESSFUL ] org.apache.commons#commons-compress;1.4.1!commons-compress.jar (29ms)\\ndownloading https://repo1.maven.org/maven2/org/tukaani/xz/1.0/xz-1.0.jar ...\\n\\t[SUCCESSFUL ] org.tukaani#xz;1.0!xz.jar (17ms)\\n:: resolution report :: resolve 2786ms :: artifacts dl 1303ms\\n\\t:: modules in use:\\n\\tcom.databricks#spark-avro_2.11;4.0.0 from central in [default]\\n\\tcom.databricks#spark-xml_2.11;0.4.1 from central in [default]\\n\\tcom.thoughtworks.paranamer#paranamer;2.3 from central in [default]\\n\\tcom.typesafe.scala-logging#scala-logging-api_2.11;2.1.2 from central in [default]\\n\\tcom.typesafe.scala-logging#scala-logging-slf4j_2.11;2.1.2 from central in [default]\\n\\tgraphframes#graphframes;0.5.0-spark2.1-s_2.11 from spark-packages in [default]\\n\\torg.apache.avro#avro;1.7.6 from central in [default]\\n\\torg.apache.commons#commons-compress;1.4.1 from central in [default]\\n\\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\\n\\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\\n\\torg.scala-lang#scala-reflect;2.11.0 from central in [default]\\n\\torg.slf4j#slf4j-api;1.7.7 from central in [default]\\n\\torg.tukaani#xz;1.0 from central in [default]\\n\\torg.xerial.snappy#snappy-java;1.0.5 from central in [default]\\n\\t:: evicted modules:\\n\\torg.slf4j#slf4j-api;1.7.5 by [org.slf4j#slf4j-api;1.7.7] in [default]\\n\\torg.slf4j#slf4j-api;1.6.4 by [org.slf4j#slf4j-api;1.7.7] in [default]\\n\\t---------------------------------------------------------------------\\n\\t|                  |            modules            ||   artifacts   |\\n\\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\\n\\t---------------------------------------------------------------------\\n\\t|      default     |   16  |   14  |   14  |   2   ||   14  |   14  |\\n\\t---------------------------------------------------------------------\\n:: retrieving :: org.apache.spark#spark-submit-parent\\n\\tconfs: [default]\\n\\t14 artifacts copied, 0 already retrieved (7998kB/25ms)\\n18/11/29 04:17:39 INFO org.spark_project.jetty.util.log: Logging initialized @6948ms\\n18/11/29 04:17:39 INFO org.spark_project.jetty.server.Server: jetty-9.3.z-SNAPSHOT\\n18/11/29 04:17:39 INFO org.spark_project.jetty.server.Server: Started @7028ms\\n18/11/29 04:17:39 INFO org.spark_project.jetty.server.AbstractConnector: Started ServerConnector@7ad06a4d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\\n18/11/29 04:17:39 INFO com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase: GHFS version: 1.6.10-hadoop2\\n18/11/29 04:17:40 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at testcluster-m/10.128.0.3:8032\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/com.databricks_spark-xml_2.11-0.4.1.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/graphframes_graphframes-0.5.0-spark2.1-s_2.11.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/com.databricks_spark-avro_2.11-4.0.0.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/com.typesafe.scala-logging_scala-logging-api_2.11-2.1.2.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/com.typesafe.scala-logging_scala-logging-slf4j_2.11-2.1.2.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/org.scala-lang_scala-reflect-2.11.0.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/org.apache.avro_avro-1.7.6.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.3.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/org.xerial.snappy_snappy-java-1.0.5.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/org.apache.commons_commons-compress-1.4.1.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 WARN org.apache.spark.deploy.yarn.Client: Same path resource file:/root/.ivy2/jars/org.tukaani_xz-1.0.jar added multiple times to distributed cache.\\n18/11/29 04:17:44 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1543464910529_0001\\n['_c0', '_c1', '_c2', '_c3', '_c4', '_c5', '_c6', '_c7', '_c8', '_c9', '_c10', '_c11', '_c12', '_c13', '_c14', '_c15', '_c16', '_c17', '_c18', '_c19', '_c20', '_c21', '_c22', '_c23', '_c24', '_c25', '_c26', '_c27', '_c28', '_c29', '_c30', '_c31', '_c32', '_c33', '_c34', '_c35', '_c36', '_c37', '_c38', '_c39']\\n18/11/29 04:17:59 WARN org.apache.spark.util.Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\\n\\r[Stage 1:>                                                         (0 + 6) / 84]\\r[Stage 1:=>                                                        (2 + 6) / 84]\\r[Stage 1:==>                                                       (4 + 6) / 84]\\r[Stage 1:===>                                                      (5 + 6) / 84]\\r[Stage 1:====>                                                     (7 + 6) / 84]\\r[Stage 1:=====>                                                    (8 + 6) / 84]\\r[Stage 1:======>                                                  (10 + 6) / 84]\\r[Stage 1:=======>                                                 (11 + 6) / 84]\\r[Stage 1:========>                                                (12 + 6) / 84]\\r[Stage 1:==========>                                              (15 + 6) / 84]\\r[Stage 1:==========>                                              (16 + 6) / 84]\\r[Stage 1:===========>                                             (17 + 6) / 84]\\r[Stage 1:============>                                            (18 + 6) / 84]\\r[Stage 1:============>                                            (19 + 6) / 84]\\r[Stage 1:=============>                                           (20 + 6) / 84]\\r[Stage 1:==============>                                          (21 + 6) / 84]\\r[Stage 1:==============>                                          (22 + 6) / 84]\\r[Stage 1:===============>                                         (23 + 6) / 84]\\r[Stage 1:================>                                        (24 + 6) / 84]\\r[Stage 1:================>                                        (25 + 6) / 84]\\r[Stage 1:=================>                                       (26 + 6) / 84]\\r[Stage 1:===================>                                     (28 + 6) / 84]\\r[Stage 1:====================>                                    (30 + 6) / 84]\\r[Stage 1:=====================>                                   (31 + 6) / 84]\\r[Stage 1:=====================>                                   (32 + 6) / 84]\\r[Stage 1:======================>                                  (33 + 6) / 84]\\r[Stage 1:=======================>                                 (34 + 6) / 84]\\r[Stage 1:=======================>                                 (35 + 6) / 84]\\r[Stage 1:========================>                                (36 + 6) / 84]\\r[Stage 1:=========================>                               (37 + 6) / 84]\\r[Stage 1:=========================>                               (38 + 6) / 84]\\r[Stage 1:==========================>                              (39 + 6) / 84]\\r[Stage 1:===========================>                             (40 + 6) / 84]\\r[Stage 1:===========================>                             (41 + 6) / 84]\\r[Stage 1:=============================>                           (43 + 6) / 84]\\r[Stage 1:=============================>                           (44 + 6) / 84]\\r[Stage 1:==============================>                          (45 + 6) / 84]\\r[Stage 1:===============================>                         (46 + 6) / 84]\\r[Stage 1:===============================>                         (47 + 6) / 84]\\r[Stage 1:================================>                        (48 + 6) / 84]\\r[Stage 1:=================================>                       (49 + 6) / 84]\\r[Stage 1:=================================>                       (50 + 6) / 84]\\r[Stage 1:==================================>                      (51 + 6) / 84]\\r[Stage 1:===================================>                     (52 + 6) / 84]\\r[Stage 1:===================================>                     (53 + 6) / 84]\\r[Stage 1:=====================================>                   (55 + 6) / 84]\\r[Stage 1:======================================>                  (56 + 6) / 84]\\r[Stage 1:=======================================>                 (58 + 6) / 84]\\r[Stage 1:========================================>                (60 + 6) / 84]\\r[Stage 1:=========================================>               (61 + 6) / 84]\\r[Stage 1:==========================================>              (62 + 6) / 84]\\r[Stage 1:===========================================>             (64 + 6) / 84]\\r[Stage 1:============================================>            (65 + 6) / 84]\\r[Stage 1:============================================>            (66 + 6) / 84]\\r[Stage 1:=============================================>           (67 + 6) / 84]\\r[Stage 1:==============================================>          (69 + 6) / 84]\\r[Stage 1:===============================================>         (70 + 6) / 84]\\r[Stage 1:================================================>        (71 + 6) / 84]\\r[Stage 1:================================================>        (72 + 6) / 84]\\r[Stage 1:=================================================>       (73 + 6) / 84]\\r[Stage 1:==================================================>      (74 + 6) / 84]\\r[Stage 1:==================================================>      (75 + 6) / 84]\\r[Stage 1:===================================================>     (76 + 6) / 84]\\r[Stage 1:====================================================>    (77 + 6) / 84]\\r[Stage 1:====================================================>    (78 + 6) / 84]\\r[Stage 1:=====================================================>   (79 + 5) / 84]\\r[Stage 1:======================================================>  (80 + 4) / 84]\\r[Stage 1:======================================================>  (81 + 3) / 84]\\r[Stage 1:=======================================================> (82 + 2) / 84]\\r[Stage 1:========================================================>(83 + 1) / 84]\\r                                                                                \\r9164811\\n\\r[Stage 3:>                                                         (0 + 6) / 84]\\r[Stage 3:=>                                                        (2 + 6) / 84]\\r[Stage 3:===>                                                      (5 + 6) / 84]\\r[Stage 3:====>                                                     (6 + 6) / 84]\\r[Stage 3:=====>                                                    (8 + 6) / 84]\\r[Stage 3:======>                                                   (9 + 6) / 84]\\r[Stage 3:=======>                                                 (11 + 6) / 84]\\r[Stage 3:========>                                                (13 + 6) / 84]\\r[Stage 3:=========>                                               (14 + 6) / 84]\\r[Stage 3:==========>                                              (15 + 6) / 84]\\r[Stage 3:==========>                                              (16 + 6) / 84]\\r[Stage 3:===========>                                             (17 + 6) / 84]\\r[Stage 3:============>                                            (18 + 6) / 84]\\r[Stage 3:============>                                            (19 + 6) / 84]\\r[Stage 3:=============>                                           (20 + 6) / 84]\\r[Stage 3:==============>                                          (21 + 6) / 84]\\r[Stage 3:==============>                                          (22 + 6) / 84]\\r[Stage 3:================>                                        (24 + 6) / 84]\\r[Stage 3:=================>                                       (26 + 6) / 84]\\r[Stage 3:==================>                                      (27 + 6) / 84]\\r[Stage 3:===================>                                     (28 + 6) / 84]\\r[Stage 3:===================>                                     (29 + 6) / 84]\\r[Stage 3:====================>                                    (30 + 6) / 84]\\r[Stage 3:=====================>                                   (31 + 6) / 84]\\r[Stage 3:=====================>                                   (32 + 6) / 84]\\r[Stage 3:======================>                                  (33 + 6) / 84]\\r[Stage 3:=======================>                                 (34 + 6) / 84]\\r[Stage 3:========================>                                (36 + 6) / 84]\\r[Stage 3:=========================>                               (37 + 6) / 84]\\r[Stage 3:==========================>                              (39 + 6) / 84]\\r[Stage 3:===========================>                             (40 + 6) / 84]\\r[Stage 3:============================>                            (42 + 6) / 84]\\r[Stage 3:=============================>                           (43 + 6) / 84]\\r[Stage 3:=============================>                           (44 + 6) / 84]\\r[Stage 3:==============================>                          (45 + 6) / 84]\\r[Stage 3:===============================>                         (46 + 6) / 84]\\r[Stage 3:================================>                        (48 + 6) / 84]\\r[Stage 3:=================================>                       (49 + 6) / 84]\\r[Stage 3:=================================>                       (50 + 6) / 84]\\r[Stage 3:==================================>                      (51 + 6) / 84]\\r[Stage 3:===================================>                     (52 + 6) / 84]\\r[Stage 3:===================================>                     (53 + 6) / 84]\\r[Stage 3:====================================>                    (54 + 6) / 84]\\r[Stage 3:=====================================>                   (55 + 6) / 84]\\r[Stage 3:======================================>                  (56 + 6) / 84]\\r[Stage 3:======================================>                  (57 + 6) / 84]\\r[Stage 3:=======================================>                 (58 + 6) / 84]\\r[Stage 3:========================================>                (59 + 6) / 84]\\r[Stage 3:========================================>                (60 + 6) / 84]\\r[Stage 3:=========================================>               (61 + 6) / 84]\\r[Stage 3:==========================================>              (62 + 6) / 84]\\r[Stage 3:==========================================>              (63 + 6) / 84]\\r[Stage 3:===========================================>             (64 + 6) / 84]\\r[Stage 3:============================================>            (65 + 6) / 84]\\r[Stage 3:============================================>            (66 + 6) / 84]\\r[Stage 3:==============================================>          (68 + 6) / 84]\\r[Stage 3:==============================================>          (69 + 6) / 84]\\r[Stage 3:===============================================>         (70 + 6) / 84]\\r[Stage 3:================================================>        (71 + 6) / 84]\\r[Stage 3:================================================>        (72 + 6) / 84]\\r[Stage 3:=================================================>       (73 + 6) / 84]\\r[Stage 3:==================================================>      (74 + 6) / 84]\\r[Stage 3:==================================================>      (75 + 6) / 84]\\r[Stage 3:===================================================>     (76 + 6) / 84]\\r[Stage 3:====================================================>    (77 + 6) / 84]\\r[Stage 3:====================================================>    (78 + 6) / 84]\\r[Stage 3:=====================================================>   (79 + 5) / 84]\\r[Stage 3:======================================================>  (80 + 4) / 84]\\r[Stage 3:=======================================================> (82 + 2) / 84]\\r[Stage 3:========================================================>(83 + 1) / 84]\\r                                                                                \\r36675806\\n18/11/29 04:22:45 INFO org.spark_project.jetty.server.AbstractConnector: Stopped Spark@7ad06a4d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\\n\"\n",
      "Tearing down cluster\n"
     ]
    }
   ],
   "source": [
    "!python submit_job_to_cluster.py --project_id=w261-222623 --zone=us-central1-b --cluster_name=testcluster --gcs_bucket=w261_final_project --key_file=$HOME/w261.json --create_new_cluster --pyspark_file=eda.py --instance_type=n1-standard-4 --worker_nodes=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results from running EDA code above:\n",
    "number of testing data rows, $n_{test}=9164811$<br>\n",
    "number of training data rows, $n=36675806$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of Course Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
